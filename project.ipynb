{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0b09603c",
   "metadata": {},
   "source": [
    "# CHUNKING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2ecda751",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import re\n",
    "import tiktoken\n",
    "from docx import Document\n",
    "from PyPDF2 import PdfReader\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "import pdfplumber"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c28cb706",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_law_header(text):\n",
    "    \"\"\"\n",
    "    Tìm \"Chương I\" và lấy từ đó trở đi (Điều 1 nằm TRONG Chương I).\n",
    "    \"\"\"\n",
    "    pattern = r\"(Chương\\s+[I1])\"\n",
    "    match = re.search(pattern, text, flags=re.IGNORECASE)\n",
    "\n",
    "    if match:\n",
    "        # Lấy từ \"Chương I\" trở đi (Điều 1 nằm sau đó)\n",
    "        return text[match.start():]\n",
    "    else:\n",
    "        # Không tìm thấy Chương I => giữ nguyên\n",
    "        return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "64b084c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_text(pdf_path):\n",
    "    text = \"\"\n",
    "    with pdfplumber.open(pdf_path) as pdf:\n",
    "        for page in pdf.pages:\n",
    "            page_text = page.extract_text()\n",
    "            if page_text:\n",
    "                text += page_text + \"\\n\"\n",
    "    return text\n",
    "\n",
    "def clean_text(t):\n",
    "    \"\"\"Giữ lại newline để regex tách điều\"\"\"\n",
    "    t = t.replace(\"\\xa0\", \" \")\n",
    "    t = re.sub(r\"[ \\t]+\", \" \", t)  # ✅ Chỉ compress space/tab, giữ \\n\n",
    "    return t.strip()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8c04f47d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Tách điều-khoản\n",
    "\n",
    "regex_dieu = re.compile(r\"(?m)^(Điều\\s+\\d+)\\.\")   # dạng: \"Điều 1.\"\n",
    "regex_khoan = re.compile(r\"(?<=\\n|\\s)(\\d{1,2})\\.(?=\\s)\")   # dạng: \"1. \"\n",
    "regex_diem = re.compile(r\"^[a-z]\\)$\")  \n",
    "\n",
    "def split_by_dieu(text):\n",
    "    parts = regex_dieu.split(text)\n",
    "    results = []\n",
    "    \n",
    "    for i in range(1,len(parts), 2):\n",
    "        if i + 1 < len(parts):\n",
    "            dieu_title = parts[i].strip()\n",
    "            dieu_content = parts[i+1].strip()\n",
    "            results.append((dieu_title, dieu_content))\n",
    "\n",
    "    return results\n",
    "\n",
    "def split_by_khoan(dieu_content):\n",
    "    parts = regex_khoan.split(dieu_content)\n",
    "    results = []\n",
    "\n",
    "    for i in range(1, len(parts), 2):\n",
    "        khoan_num = parts[i]\n",
    "        khoan_content = parts[i+1].strip()\n",
    "        results.append((khoan_num, khoan_content))\n",
    "\n",
    "    return results\n",
    "\n",
    "\n",
    "def split_by_diem(khoan_content):\n",
    "    parts = regex_diem.split(khoan_content)\n",
    "    results = []\n",
    "\n",
    "    for i in range(1, len(parts), 2):\n",
    "        diem_letter = parts[i]\n",
    "        diem_content = parts[i+1].strip()\n",
    "        results.append((diem_letter, diem_content))\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f43229c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Đo token\n",
    "\n",
    "def count_tokens(text):\n",
    "    return len(text.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6a7cf3f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_chunks(law_name, text):\n",
    "    chunks = []\n",
    "    ds_dieu = split_by_dieu(text)\n",
    "\n",
    "    for dieu_title, dieu_body in ds_dieu:\n",
    "        # ✅ FIX: Extract số điều từ \"Điều 2\" chứ không phải từ toàn dieu_title\n",
    "        nums = re.findall(r\"\\d+\", dieu_title)\n",
    "        if not nums:\n",
    "            continue\n",
    "        dieu_num = int(nums[0])  # ← Đây phải là 1, 2, 3, 4...\n",
    "\n",
    "        ds_khoan = split_by_khoan(dieu_body)\n",
    "\n",
    "        if not ds_khoan or len(ds_khoan) == 0:\n",
    "            chunk_id = f\"{law_name}_d{dieu_num}\"\n",
    "            chunks.append({\n",
    "                \"id\": chunk_id,\n",
    "                \"law\": law_name,\n",
    "                \"dieu\": dieu_num,  # ← Sẽ là 2, 3, 4... chứ không phải luôn 1\n",
    "                \"khoan\": None,\n",
    "                \"diem\": None,\n",
    "                \"text\": f\"[Điều {dieu_num}]: {dieu_body.strip()}\"\n",
    "            })\n",
    "            continue\n",
    "\n",
    "        for khoan_num, khoan_body in ds_khoan:\n",
    "            chunk_id = f\"{law_name}_d{dieu_num}_k{khoan_num}\"\n",
    "            \n",
    "            chunks.append({\n",
    "                \"id\": chunk_id,\n",
    "                \"law\": law_name,\n",
    "                \"dieu\": dieu_num,  # ← Sẽ là 2, 3, 4... chứ không phải luôn 1\n",
    "                \"khoan\": int(khoan_num),\n",
    "                \"diem\": None,\n",
    "                \"text\": f\"[Điều {dieu_num}] [Khoản {khoan_num}]: {khoan_body.strip()}\"\n",
    "            })\n",
    "\n",
    "    return chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "56d2ab63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tổng chunk tạo được: 338\n",
      "Đã lưu file luatgtdb_chunks.json ✔\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    PDF_PATH = \"luatgtdb.pdf\"        \n",
    "    LAW_NAME = \"35/2024/QH15\"\n",
    "\n",
    "    raw_text = extract_text(PDF_PATH)\n",
    "    clean = clean_text(raw_text)\n",
    "\n",
    "    chunks = create_chunks(LAW_NAME, clean)\n",
    "\n",
    "    print(\"Tổng chunk tạo được:\", len(chunks))\n",
    "\n",
    "    with open(\"luatgtdb_chunks.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(chunks, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "    print(\"Đã lưu file luatgtdb_chunks.json ✔\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "32739224",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langchain_google_genai import GoogleGenerativeAIEmbeddings\n",
    "from langchain_community.vectorstores import DocArrayInMemorySearch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d017d5dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gradio as gr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d64a37b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from operator import itemgetter\n",
    "import gradio as gr\n",
    "import json\n",
    "\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langchain_google_genai import GoogleGenerativeAIEmbeddings  \n",
    "from langchain_community.embeddings import FastEmbedEmbeddings\n",
    "from langchain_community.vectorstores import DocArrayInMemorySearch\n",
    "from langchain_core.documents import Document\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.chat_history import InMemoryChatMessageHistory\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain_core.runnables.history import RunnableWithMessageHistory\n",
    "from langchain_core.runnables import RunnableLambda, RunnablePassthrough"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bbf794f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CẤU HÌNH API KEY GEMINI\n",
    "os.environ[\"GOOGLE_API_KEY\"] = \"YOUR_API_HERE\"  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e46b6b9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# KHỞI TẠO LLM & EMBEDDING\n",
    "llm = ChatGoogleGenerativeAI(\n",
    "    model=\"gemini-2.5-flash\",\n",
    "    temperature=0.2,\n",
    ")\n",
    "\n",
    "embeddings = GoogleGenerativeAIEmbeddings(\n",
    "     model=\"models/text-embedding-004\"\n",
    " )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c92950ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LOAD JSON & TẠO DOCUMENTS\n",
    "JSON_PATH = \"luatgtdb_chunks.json\"   \n",
    "\n",
    "with open(JSON_PATH, \"r\", encoding=\"utf-8\") as f:\n",
    "    raw_chunks = json.load(f)   # list[dict]\n",
    "\n",
    "documents = [\n",
    "    Document(\n",
    "        page_content=item[\"text\"],\n",
    "        metadata={\n",
    "            \"id\": item.get(\"id\"),\n",
    "            \"law\": item.get(\"law\"),\n",
    "            \"dieu\": item.get(\"dieu\"),\n",
    "            \"khoan\": item.get(\"khoan\"),\n",
    "            \"diem\": item.get(\"diem\"),\n",
    "        },\n",
    "    )\n",
    "    for item in raw_chunks\n",
    "]\n",
    "\n",
    "print(f\"Đã load {len(documents)} chunks từ JSON.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d86a61d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TẠO VECTORSTORE & RETRIEVER\n",
    "\n",
    "vectorstore = DocArrayInMemorySearch.from_documents(\n",
    "    documents=documents,\n",
    "    embedding=embeddings,\n",
    ")\n",
    "\n",
    "retriever = vectorstore.as_retriever(search_kwargs={\"k\": 30})\n",
    "print(\"Vectorstore đã khởi tạo xong.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d658a703",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ĐỊNH NGHĨA HÀM FORMAT CONTEXT\n",
    "\n",
    "def format_docs(docs):\n",
    "    parts = []\n",
    "    for d in docs:\n",
    "        law = d.metadata.get(\"law\")\n",
    "        dieu = d.metadata.get(\"dieu\")\n",
    "        khoan = d.metadata.get(\"khoan\")\n",
    "        diem = d.metadata.get(\"diem\")\n",
    "        header = f\"[Luật {law} - Điều {dieu}, Khoản {khoan}\"\n",
    "        if diem:\n",
    "            header += f\", Điểm {diem}]\"\n",
    "        else:\n",
    "            header += \"]\"\n",
    "        parts.append(f\"{header}\\n{d.page_content}\")\n",
    "    return \"\\n\\n---\\n\\n\".join(parts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d11fcb58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PROMPT CHO RAG\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"Bạn là trợ lý pháp lý, trả lời dựa trên các điều khoản luật trong phần context. \"\n",
    "            \"Nếu có thể, hãy nêu rõ Điều/Khoản/Điểm.\"\n",
    "        ),\n",
    "        MessagesPlaceholder(\"chat_history\"),  # lịch sử hội thoại nhiều turn\n",
    "        (\n",
    "            \"human\",\n",
    "            \"Câu hỏi: {question}\\n\\n\"\n",
    "            \"Văn bản luật liên quan:\\n{context}\"\n",
    "        ),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a978d58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Đã load 338 chunks từ JSON.\n",
      "Vectorstore đã khởi tạo xong.\n"
     ]
    }
   ],
   "source": [
    "#XÂY DỰNG RAG CHAIN\n",
    "\n",
    "# Chain: question -> retriever -> format_docs -> prompt -> llm\n",
    "\n",
    "base_rag_chain = (\n",
    "    {\n",
    "        \"question\": itemgetter(\"question\"),\n",
    "        \"chat_history\": itemgetter(\"chat_history\"),\n",
    "        \"context\": itemgetter(\"question\")\n",
    "        | RunnableLambda(lambda q: retriever.invoke(q))\n",
    "        | RunnableLambda(format_docs),\n",
    "    }\n",
    "    | prompt\n",
    "    | llm\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0287d498",
   "metadata": {},
   "outputs": [],
   "source": [
    "_store = {} \n",
    "def get_session_history(session_id: str) -> InMemoryChatMessageHistory:\n",
    "    if session_id not in _store:\n",
    "        _store[session_id] = InMemoryChatMessageHistory()\n",
    "    return _store[session_id]\n",
    "\n",
    "\n",
    "rag_with_history = RunnableWithMessageHistory(\n",
    "    base_rag_chain,\n",
    "    get_session_history,\n",
    "    input_messages_key=\"question\",      \n",
    "    history_messages_key=\"chat_history\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "3ea8ade1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chat(message, history):\n",
    "    \"\"\"\n",
    "    message: câu mới user gửi\n",
    "    history: lịch sử hội thoại của Gradio (không cần tự xử lý, vì ta dùng InMemoryChatMessageHistory riêng)\n",
    "    \"\"\"\n",
    "    # Dùng 1 session_id cố định cho Gradio. Nếu muốn multi-user thì map theo user id/cookie.\n",
    "    session_id = \"gradio-session\"\n",
    "\n",
    "    result = rag_with_history.invoke(\n",
    "        {\"question\": message},\n",
    "        config={\"configurable\": {\"session_id\": session_id}},\n",
    "    )\n",
    "\n",
    "    # ChatGoogleGenerativeAI trả về AIMessage -> dùng .content\n",
    "    return result.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "5e37efec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7862\n",
      "* To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7862/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ngona\\anaconda3\\Lib\\site-packages\\pydantic\\v1\\main.py:1054: UserWarning: LangSmith now uses UUID v7 for run and trace identifiers. This warning appears when passing custom IDs. Please use: from langsmith import uuid7\n",
      "            id = uuid7()\n",
      "Future versions will require UUID v7.\n",
      "  input_data = validator(cls_, input_data)\n"
     ]
    }
   ],
   "source": [
    "view = gr.ChatInterface(\n",
    "    fn=chat,\n",
    "    type=\"messages\",\n",
    "    title=\"Luật 35/2024/QH15 Assistant\"\n",
    ").launch(inbrowser=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
